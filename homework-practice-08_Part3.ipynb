{"nbformat":4,"nbformat_minor":4,"metadata":{"language_info":{"pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python","version":"3.7.7","file_extension":".py"},"notebookId":"1915764a-dac4-48ee-a7ae-dfab694347c1","kernelspec":{"name":"python3","description":"IPython kernel implementation for Yandex DataSphere","spec":{"language":"python","display_name":"Yandex DataSphere Kernel","codemirror_mode":"python","argv":["/bin/true"],"env":{},"help_links":[]},"resources":{},"display_name":"Yandex DataSphere Kernel"},"ydsNotebookPath":"homework-practice_Part3.ipynb"},"cells":[{"cell_type":"markdown","source":"# Машинное обучение, ФКН ВШЭ\n\n## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n\n# ЧАСТЬ 3\n\n### Пришлось разбить на несколько файлов, чтобы иметь возможность обучать параллельно несколько заданий.","metadata":{"cellId":"d8252828-84f3-40cb-af66-89dcb05b847d"}},{"cell_type":"code","source":"#!g1.1\nimport random\n\nimport numpy as np\nimport scipy\nfrom itertools import combinations\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import Normalizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score","metadata":{"cellId":"b6f38de4-9964-471f-96fb-88222333805a","trusted":true},"outputs":[],"execution_count":363},{"cell_type":"code","source":"#!g1.1\nimport keras\nfrom keras.datasets import fashion_mnist\n(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\nx_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\nx_test = x_test_pics.reshape(x_test_pics.shape[0], -1)","metadata":{"cellId":"b8d0caeb-3c81-452e-a542-9d380dde6a6d","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"Using TensorFlow backend.\n"},{"output_type":"stream","name":"stdout","text":"Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n32768/29515 [=================================] - 0s 3us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n26427392/26421880 [==============================] - 9s 0us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n8192/5148 [===============================================] - 0s 0us/step\nDownloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n4423680/4422102 [==============================] - 3s 1us/step\n"}],"execution_count":364},{"cell_type":"markdown","source":"__Задание 5. (Максимум 2 балла)__\n\nПоэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты.","metadata":{"cellId":"a9e5f9b2-8e37-4932-8538-a1ba4dfea501"}},{"cell_type":"code","source":"#!c1.8\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass RFFPipeline_Sign(BaseEstimator, TransformerMixin): \n    def __init__(self, model, n_features=1000, new_dim=50, use_PCA=True):\n        self.n_features = n_features\n        self.use_PCA = use_PCA\n        self.normalizer = Normalizer()\n        self.new_dim = new_dim\n        self.PCA_model = PCA(new_dim)\n        self.model = model\n\n    def fit(self, X, y):\n        X = self.normalizer.fit_transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.fit_transform(X, y)\n            \n        elements_for_choosing = random.sample(range(X.shape[0]), 1420) # выбираю случ. элементы из выборки для составления пар\n        \n        dist_list = [] # список пар\n        for (c,p) in combinations(elements_for_choosing, 2): # составляю комбинации пар выборки\n            dist_list.append(list(scipy.spatial.distance.cdist(X[c].reshape(1,-1), \n                                                               X[p].reshape(1,-1),\n                                                               lambda u, v: ((u-v)**2).sum())[0]))\n        self.median = np.median(dist_list) # рассчитываю медиану\n        self.w = np.random.normal(scale=1./self.median, size=(X.shape[1], self.n_features)) # генерирую набор весов\n        self.b = np.random.uniform(-np.pi, np.pi, size=self.n_features) # генерирую набор свдигов\n        \n        new_features_X = np.sign(np.dot(X, self.w))# + self.b)\n        self.model.fit(new_features_X, y)\n        return\n    \n    def predict_proba(self, X):\n        X = self.normalizer.transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.transform(X)\n        \n        new_features_X = np.sign(np.dot(X, self.w))# + self.b)\n        return self.model.predict_proba(new_features_X)\n        \n    def predict(self, X):\n        X = self.normalizer.transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.transform(X)\n        \n        new_features_X = np.sign(np.dot(X, self.w))# + self.b)\n        return self.model.predict(new_features_X)","metadata":{"cellId":"cf552961-a637-4256-9a98-5d00065b27be","trusted":true},"outputs":[],"execution_count":372},{"cell_type":"code","source":"#!c1.8\nforest = RandomForestClassifier(random_state = 72)\nforest_rffp_kernel = RFFPipeline_Sign(model=forest)\nforest_rffp_kernel.fit(x_train, y_train)\nforest_preds = forest_rffp_kernel.predict(x_test)\nprint('SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(forest_preds, y_test)))","metadata":{"cellId":"m4d2polxvocq37ny0ac16","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: 0.86610\n\n"}],"execution_count":373},{"cell_type":"code","source":"#!c1.8\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass RFFPipeline_Sign(BaseEstimator, TransformerMixin): \n    def __init__(self, model, n_features=1000, new_dim=50, use_PCA=True):\n        self.n_features = n_features\n        self.use_PCA = use_PCA\n        self.normalizer = Normalizer()\n        self.new_dim = new_dim\n        self.PCA_model = PCA(new_dim)\n        self.model = model\n\n    def fit(self, X, y):\n        X = self.normalizer.fit_transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.fit_transform(X, y)\n            \n        elements_for_choosing = random.sample(range(X.shape[0]), 1420) # выбираю случ. элементы из выборки для составления пар\n        \n        dist_list = [] # список пар\n        for (c,p) in combinations(elements_for_choosing, 2): # составляю комбинации пар выборки\n            dist_list.append(list(scipy.spatial.distance.cdist(X[c].reshape(1,-1), \n                                                               X[p].reshape(1,-1),\n                                                               lambda u, v: ((u-v)**2).sum())[0]))\n        self.median = np.median(dist_list) # рассчитываю медиану\n        self.w = np.random.normal(scale=1./self.median, size=(X.shape[1], self.n_features)) # генерирую набор весов\n        self.b = np.random.uniform(-np.pi, np.pi, size=self.n_features) # генерирую набор свдигов\n        \n        new_features_X = np.sign(np.dot(X, self.w) + self.b)\n        self.model.fit(new_features_X, y)\n        return\n    \n    def predict_proba(self, X):\n        X = self.normalizer.transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.transform(X)\n        \n        new_features_X = np.sign(np.dot(X, self.w) + self.b)\n        return self.model.predict_proba(new_features_X)\n        \n    def predict(self, X):\n        X = self.normalizer.transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.transform(X)\n        \n        new_features_X = np.sign(np.dot(X, self.w) + self.b)\n        return self.model.predict(new_features_X)","metadata":{"cellId":"d19ri6k2y45i8hg4lvalsl"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!c1.8\nforest = RandomForestClassifier(random_state = 72)\nforest_rffp_kernel = RFFPipeline_Sign(model=forest)\nforest_rffp_kernel.fit(x_train, y_train)\nforest_preds = forest_rffp_kernel.predict(x_test)\nprint('SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(forest_preds, y_test)))","metadata":{"cellId":"c3hyrkjvcfrcgoyzifvwz","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: 0.86460\n\n"}],"execution_count":374},{"cell_type":"code","source":"#!c1.8\nforest = SVC(kernel='linear', random_state = 72)\nforest_rffp_kernel = RFFPipeline_Sign(model=forest)\nforest_rffp_kernel.fit(x_train, y_train)\nforest_preds = forest_rffp_kernel.predict(x_test)\nprint('SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(forest_preds, y_test)))","metadata":{"cellId":"cnawaarreqhxdg5s894yta","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: 0.82940\n\n"}],"execution_count":375},{"cell_type":"markdown","source":"**Вывод:** Поэкспериментировал со знаком от скалярного произведения в качестве случайных признаков, а также со случайным лесом в качестве альтернативного классификатора. Лучшего качества, к сожалению, добиться не удалось. Была мысль ещё попробовать функцию Лапласса, но реализовать не успел.","metadata":{"cellId":"w4vfso0wusq8t74xguv3i"}}]}