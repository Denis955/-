{"nbformat":4,"nbformat_minor":4,"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.7.7","file_extension":".py","pygments_lexer":"ipython3","mimetype":"text/x-python","name":"python","codemirror_mode":{"name":"ipython","version":3}},"notebookId":"1915764a-dac4-48ee-a7ae-dfab694347c1","kernelspec":{"name":"python3","description":"IPython kernel implementation for Yandex DataSphere","spec":{"language":"python","display_name":"Yandex DataSphere Kernel","codemirror_mode":"python","argv":["/bin/true"],"env":{},"help_links":[]},"resources":{},"display_name":"Yandex DataSphere Kernel"},"ydsNotebookPath":"homework-practice-08_Part1.ipynb"},"cells":[{"cell_type":"markdown","source":"# Машинное обучение, ФКН ВШЭ\n\n## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n\n### Общая информация\nДата выдачи: 1.10.2021\n\nМягкий дедлайн: 17.10.2021 23:59 МСК\n\nЖесткий дедлайн: 24.10.2021 23:59 МСК (1 неделя -- минус балл)\n\n### Оценивание и штрафы\nКаждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n\nСдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n\nЗадание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n\nНеэффективная реализация кода может негативно отразиться на оценке.\n\n### Формат сдачи\nЗагрузите решение в свой репозиторий на github и поделитесь [ссылкой на решение в форме](https://forms.gle/ZzCaqRj6bmfpSpyL7). Не забудьте дать доступ к Вашему репозиторию, что у преподавателей была возмоожность проверить работу.","metadata":{"cellId":"d8252828-84f3-40cb-af66-89dcb05b847d"}},{"cell_type":"markdown","source":"### О задании\n\nНа занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n\nЯдровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n\nМы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n$$\\tilde \\varphi(x) = (\n\\cos (w_1^T x + b_1),\n\\dots,\n\\cos (w_n^T x + b_n)\n),$$\nгде $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n\nНа новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n\nМожно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n\n### Алгоритм\n\nВам потребуется реализовать следующий алгоритм:\n1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n4. Сформировать n_features новых признаков по формулам, приведённым выше.\n5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель.","metadata":{"cellId":"bdd151a2-7a61-4e60-acef-1da82789f009"}},{"cell_type":"markdown","source":"Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки.","metadata":{"cellId":"5c744995-060c-4ab5-be8b-d85904c5a913"}},{"cell_type":"code","source":"#!c1.8\nimport random\n\nimport numpy as np\nimport scipy\nfrom scipy.stats import chi\nfrom itertools import combinations\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import Normalizer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nimport lightgbm as lgbm\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score","metadata":{"cellId":"b6f38de4-9964-471f-96fb-88222333805a","trusted":true},"outputs":[],"execution_count":408},{"cell_type":"code","source":"#!g1.1\nimport keras\nfrom keras.datasets import fashion_mnist\n(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\nx_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\nx_test = x_test_pics.reshape(x_test_pics.shape[0], -1)","metadata":{"cellId":"b8d0caeb-3c81-452e-a542-9d380dde6a6d","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"Using TensorFlow backend.\n"}],"execution_count":3},{"cell_type":"markdown","source":"__Задание 1. (5 баллов)__\n\nРеализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n\nВаша реализация должна поддерживать следующие опции:\n1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n\nПротестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно.","metadata":{"cellId":"bacd0edb-085e-4b4e-b5d7-1a8e424695d5"}},{"cell_type":"code","source":"#!c1.8\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass RFFPipeline(BaseEstimator, TransformerMixin): \n    \"\"\"\n    При унаследовании от TransformerMixin, fit_transformer() можно не задавать, \n    Если добавить в качестве базового класса BaseEstimator и не реализовывать *args, **kwargs в конструкторе,\n    то будут доступны методы get_params() и set_params()\n    \"\"\"\n    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n        \"\"\"        \n        Implements pipeline, which consists of PCA decomposition,\n        Random Fourier Features approximation and linear classification model.\n        \n        n_features, int: amount of synthetic random features generated with RFF approximation.\n\n        new_dim, int: PCA output size.\n        \n        use_PCA, bool: whether to include PCA preprocessing.\n        \n        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n        \n        Feel free to edit this template for your preferences.    \n        \"\"\"\n        self.n_features = n_features\n        self.use_PCA = use_PCA\n        self.normalizer = Normalizer()\n        self.new_dim = new_dim\n        self.PCA_model = PCA(new_dim)\n        self.classifier = classifier\n        if self.classifier == 'logreg':\n            self.model = LogisticRegression(max_iter = 500, n_jobs = -1, random_state = 72)\n        else:\n            self.model = SVC(kernel='linear', random_state = 72)\n        \n    def fit(self, X, y):\n        \"\"\"\n        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n        \"\"\"\n        X = self.normalizer.fit_transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.fit_transform(X, y)\n            print('PCA применён')\n            \n        elements_for_choosing = random.sample(range(X.shape[0]), 1420) # выбираю случ. элементы из выборки для составления пар\n        \n        dist_list = [] # список пар\n        for (c,p) in combinations(elements_for_choosing, 2): # составляю комбинации пар выборки\n            dist_list.append(list(scipy.spatial.distance.cdist(X[c].reshape(1,-1), \n                                                               X[p].reshape(1,-1),\n                                                               lambda u, v: ((u-v)**2).sum())[0]))\n        self.median = np.median(dist_list) # рассчитываю медиану\n        print('Медиана посчитана: {:.5f}'.format(self.median))\n        self.w = np.random.normal(scale=1./self.median, size=(X.shape[1], self.n_features)) # генерирую набор весов\n        self.b = np.random.uniform(-np.pi, np.pi, size=self.n_features) # генерирую набор свдигов\n        \n        new_features_X = np.cos(np.dot(X, self.w) + self.b)\n        self.model.fit(new_features_X, y)\n        return\n    \n    def predict_proba(self, X):\n        \"\"\"\n        Apply pipeline to obtain scores for input data.\n        \"\"\"\n        X = self.normalizer.transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.transform(X)\n        \n        new_features_X = np.cos(np.dot(X, self.w) + self.b)\n        return self.model.predict_proba(new_features_X)\n        \n    def predict(self, X):\n        \"\"\"\n        Apply pipeline to obtain discrete predictions for input data.\n        \"\"\"\n        X = self.normalizer.transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.transform(X)\n        \n        new_features_X = np.cos(np.dot(X, self.w) + self.b)\n        return self.model.predict(new_features_X)","metadata":{"cellId":"r8p2dof98ul4ph6cg81y","trusted":true},"outputs":[],"execution_count":409},{"cell_type":"code","source":"#!g1.1\nrffp_kernel = RFFPipeline()\nrffp_kernel.fit(x_train, y_train)\n\npreds = rffp_kernel.predict(x_test)\nprint('Доля верных ответов на тестовой выборке:', accuracy_score(preds, y_test))","metadata":{"cellId":"c496fa65-6bbd-4be1-8948-29eb3ee3833c"},"outputs":[{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"},{"output_type":"stream","name":"stdout","text":"PCA применён\nМедиана посчитана: 0.62363\nДоля верных ответов на тестовой выборке: 0.8888666666666667\n"}],"execution_count":351},{"cell_type":"code","source":"#!g1.1\n# Применение модели с другими параметрами:\nrffp_kernel = RFFPipeline(n_features=3000, use_PCA=False, classifier='svm')\nrffp_kernel.fit(x_train, y_train)\n\npreds = rffp_kernel.predict(x_test)\nprint('Доля верных ответов на тестовой выборке:', accuracy_score(preds, y_test))","metadata":{"cellId":"lklac3yp03pplhb0mf90r"},"outputs":[{"output_type":"stream","name":"stdout","text":"Доля верных ответов на тестовой выборке: 0.8679\n"}],"execution_count":354},{"cell_type":"code","source":"#!g1.1\n# Применение модели с другими параметрами:\nrffp_kernel = RFFPipeline(n_features=500, new_dim=40)\nrffp_kernel.fit(x_train, y_train)\npreds = rffp_kernel.predict(x_test)\nprint('Доля верных ответов на тестовой выборке: {:.5f}'.format(accuracy_score(preds, y_test)))","metadata":{"cellId":"xngwdz3la4n3tdcr6ky2n"},"outputs":[{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"},{"output_type":"stream","name":"stdout","text":"PCA применён\nМедиана посчитана: 0.61542\nДоля верных ответов на тестовой выборке: 0.85810\n"}],"execution_count":355},{"cell_type":"markdown","source":"__Задание 2. (3 балла)__\n\nСравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n\nСравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n\nСделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения.","metadata":{"cellId":"8f796bd5-3dde-4b54-9537-46b421e7664c"}},{"cell_type":"code","source":"#!c1.8 # линеный SVM на случайных признаках\n%%time\nlinear2_rffp_kernel = RFFPipeline(classifier='svm')\nlinear2_rffp_kernel.fit(x_train, y_train)\npreds = linear2_rffp_kernel.predict(x_test)\nprint('Линеный SVM на случайных признаках. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(preds, y_test)))","metadata":{"cellId":"jtpzlzkihbazdbdhwex4pk","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"PCA применён\nМедиана посчитана: 0.63925\nЛиненый SVM на случайных признаках. Доля верных ответов на тестовой выборке: 0.88130\n\nCPU times: user 17min 10s, sys: 21.8 s, total: 17min 32s\nWall time: 17min 14s\n"}],"execution_count":372},{"cell_type":"code","source":"#!c1.8 # линеный SVM на случайных признаках\n%%time\nlinear_rffp_kernel = RFFPipeline(n_features=3000, classifier='svm')\nlinear_rffp_kernel.fit(x_train, y_train)\npreds = linear_rffp_kernel.predict(x_test)\nprint('Линеный SVM на случайных признаках. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(preds, y_test)))","metadata":{"cellId":"v6edo0sfrpf53gyiup91g3","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"PCA применён\nМедиана посчитана: 0.62804\nЛиненый SVM на случайных признаках. Доля верных ответов на тестовой выборке: 0.88150\n\nCPU times: user 48min 28s, sys: 24.1 s, total: 48min 52s\nWall time: 48min 34s\n"}],"execution_count":373},{"cell_type":"code","source":"#!c1.8\n# нормирую вектора\nx_train_normed = Normalizer().fit_transform(x_train)\nx_test_normed = Normalizer().transform(x_test)","metadata":{"cellId":"sk2opr5dqci2r3g1fe2cof","trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"#!c1.8 # линеный SVM на исходных признаках\n%%time\nlinear_svm = SVC(kernel='linear')\nlinear_svm.fit(x_train_normed, y_train)\nlinear_preds = linear_svm.predict(x_test_normed)\nprint('Линеный SVM на исходных признаках. Доля верных ответов на тестовой выборке: {:.5f}'.format(accuracy_score(linear_preds, y_test)))","metadata":{"cellId":"yx08ic49prxztohrerbi","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Линеный SVM на исходных признаках. Доля верных ответов на тестовой выборке: 0.85320\nCPU times: user 14min 24s, sys: 1.27 s, total: 14min 25s\nWall time: 14min 36s\n"}],"execution_count":370},{"cell_type":"markdown","source":"**Сравнение обучения SVM на случайных и исходных признаках**: Качество предсказаний SVM на исходных признаках ниже качества на случайных признаках. Однако на исходных признаках линейный SVM обучается гораздо быстрее. \n\nС увеличением числа случайных признаков, качество предсказаний увеличивается.","metadata":{"cellId":"u1628at1cqfho26kmr64t"}},{"cell_type":"code","source":"#!c1.8\n# для применения нелинейного SVM на случайных признаках необходимо немного отредактировать класс\n\n\n\nclass RFFPipeline_New(BaseEstimator, TransformerMixin): \n    def __init__(self, model, n_features=1000, new_dim=50, use_PCA=True):\n        self.n_features = n_features\n        self.use_PCA = use_PCA\n        self.normalizer = Normalizer()\n        self.new_dim = new_dim\n        self.PCA_model = PCA(new_dim)\n        self.model = model\n\n    def fit(self, X, y):\n        X = self.normalizer.fit_transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.fit_transform(X, y)\n            \n        elements_for_choosing = random.sample(range(X.shape[0]), 1420) # выбираю случ. элементы из выборки для составления пар\n        \n        dist_list = [] # список пар\n        for (c,p) in combinations(elements_for_choosing, 2): # составляю комбинации пар выборки\n            dist_list.append(list(scipy.spatial.distance.cdist(X[c].reshape(1,-1), \n                                                               X[p].reshape(1,-1),\n                                                               lambda u, v: ((u-v)**2).sum())[0]))\n        self.median = np.median(dist_list) # рассчитываю медиану\n        self.w = np.random.normal(scale=1./self.median, size=(X.shape[1], self.n_features)) # генерирую набор весов\n        self.b = np.random.uniform(-np.pi, np.pi, size=self.n_features) # генерирую набор свдигов\n        \n        new_features_X = np.cos(np.dot(X, self.w) + self.b)\n        self.model.fit(new_features_X, y)\n        return\n    \n    def predict_proba(self, X):\n        X = self.normalizer.transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.transform(X)\n        \n        new_features_X = np.cos(np.dot(X, self.w) + self.b)\n        return self.model.predict_proba(new_features_X)\n        \n    def predict(self, X):\n        X = self.normalizer.transform(X)\n        if self.use_PCA:\n            X = self.PCA_model.transform(X)\n        \n        new_features_X = np.cos(np.dot(X, self.w) + self.b)\n        return self.model.predict(new_features_X)","metadata":{"cellId":"klr37dhho1fezqzq22p1v9","trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"#!c1.8 # SVM с rbf-ядром на случайных признаках\n%%time\nrbf_kernel = SVC(kernel='rbf', random_state = 72)\nunlinear_rffp_kernel = RFFPipeline_New(model=rbf_kernel)\nunlinear_rffp_kernel.fit(x_train, y_train)\nrbf_preds = unlinear_rffp_kernel.predict(x_test)\nprint('SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(rbf_preds, y_test)))","metadata":{"cellId":"p18fg2blwgfzmdv1tn8wmj","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: 0.87500\n\nCPU times: user 17min 52s, sys: 21.3 s, total: 18min 13s\nWall time: 17min 45s\n"}],"execution_count":11},{"cell_type":"code","source":"#!c1.8 # SVM с rbf-ядром на случайных признаках\n%%time\nrbf_kernel = SVC(kernel='rbf')\nunlinear_rffp_kernel = RFFPipeline_New(model=rbf_kernel, n_features=3000)\nunlinear_rffp_kernel.fit(x_train, y_train)\nrbf_preds = unlinear_rffp_kernel.predict(x_test)\nprint('SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(rbf_preds, y_test)))","metadata":{"cellId":"cu8r7wmejhep9pewu32es","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"SVM с rbf-ядром на случайных признаках. Доля верных ответов на тестовой выборке: 0.87450\n\nCPU times: user 45min 56s, sys: 21.4 s, total: 46min 17s\nWall time: 45min 49s\n"}],"execution_count":378},{"cell_type":"code","source":"#!c1.8 # SVM с rbf-ядром на исходных признаках\n%%time\nrbf_svm = SVC(kernel='rbf').fit(x_train_normed, y_train)\nrbf2_preds = rbf_svm.predict(x_test_normed)\nprint('SVM с rbf-ядром на исходных признаках. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(rbf2_preds, y_test)))","metadata":{"cellId":"52vo1ltpadc1nutpqw9zxm","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"SVM с rbf-ядром на исходных признаках. Доля верных ответов на тестовой выборке: 0.88400\n\nCPU times: user 13min 50s, sys: 1.53 s, total: 13min 52s\nWall time: 14min 18s\n"}],"execution_count":377},{"cell_type":"code","source":"#!c1.8\n%%time\nunlinear_rffp_kernel.fit(x_train, y_train)","metadata":{"cellId":"egkxui6xaclrurkqn9so6","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"CPU times: user 33min 18s, sys: 21.8 s, total: 33min 40s\nWall time: 33min 12s\n"}],"execution_count":379},{"cell_type":"code","source":"#!c1.8\n%%time\nlinear_rffp_kernel = RFFPipeline(n_features=3000, classifier='svm')\nlinear_rffp_kernel.fit(x_train, y_train)","metadata":{"cellId":"2dlcujkfd0qmopjdrvc1","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"PCA применён\nМедиана посчитана: 0.63138\nCPU times: user 37min 21s, sys: 28.2 s, total: 37min 50s\nWall time: 38min 2s\n"}],"execution_count":381},{"cell_type":"markdown","source":"**Сравнение обучения ядрового и линейного SVM на случайных и исходных признаках:** На исходных признаках ядровой SVM показал качество лучше, чем линейный SVM. Качество оказалось даже лучше, чем у линейного SVM на случайных признаках.","metadata":{"cellId":"27b3hhwq26v4hlljbm88ee"}},{"cell_type":"markdown","source":"**Сравнение обучения ядрового и линейного SVM:** Время обучения линейного SVM и ядрового на восьмиядерной машине не сильно разнится. SVM с rbf-ядром получилось обучить даже быстрее, чем линейный. Однако качество предсказаний SVM с rbf-ядром на случайных признаках получилось хуже, чем у линейного SVM.","metadata":{"cellId":"kvyt1ioyect5gjykycp6xl"}},{"cell_type":"markdown","source":"#### Подбор числа деревьев и длины шага для LightGBM:","metadata":{"cellId":"01uq4a5p1ps1q3rw3fp6kpi"}},{"cell_type":"code","source":"#!g1.1\n# понижаю размерность для обучения Light-gbm\npca = PCA(n_components = 50)\nx_train_pca = pca.fit_transform(x_train_normed, y_train)\nx_test_pca = pca.transform(x_test_normed)","metadata":{"cellId":"c5bsadn6vy4ntg5vpvncq","trusted":true},"outputs":[],"execution_count":398},{"cell_type":"code","source":"#!g1.1\nlr = np.logspace(-4, 1, 10)\ntrees_number = [100, 200, 350]\ntuned_parameters = {'num_iterations' : trees_number, 'learning_rate' : lr, 'device' : ['gpu']}\n\nclf = GridSearchCV(lgbm.LGBMClassifier(), tuned_parameters, cv=5, scoring='accuracy', n_jobs=-1, verbose=3)\nclf.fit(x_train_pca, y_train)","metadata":{"cellId":"oj4559r9u8q2pusmlw61nm","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"},{"output_type":"stream","name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  4.8min\n[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 31.3min\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 32.8min finished\n/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"},{"output_type":"display_data","data":{"text/plain":"GridSearchCV(cv=5, error_score=nan,\n             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n                                      colsample_bytree=1.0,\n                                      importance_type='split',\n                                      learning_rate=0.1, max_depth=-1,\n                                      min_child_samples=20,\n                                      min_child_weight=0.001,\n                                      min_split_gain=0.0, n_estimators=100,\n                                      n_jobs=-1, num_leaves=31, objective=None,\n                                      random_state=None, reg_alpha=0.0,\n                                      reg_lambda=0.0, silent=Tru...\n             iid='deprecated', n_jobs=-1,\n             param_grid={'device': ['gpu'],\n                         'learning_rate': array([1.00000000e-04, 3.59381366e-04, 1.29154967e-03, 4.64158883e-03,\n       1.66810054e-02, 5.99484250e-02, 2.15443469e-01, 7.74263683e-01,\n       2.78255940e+00, 1.00000000e+01]),\n                         'num_iterations': [100, 200, 350]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='accuracy', verbose=3)"},"metadata":{}}],"execution_count":394},{"cell_type":"code","source":"#!g1.1\n%%time\nlgbm_clf = lgbm.LGBMClassifier(**clf.best_params_)\nlgbm_clf.fit(x_train_pca, y_train)\nlgbm_preds = lgbm_clf.predict(x_test_pca)\nprint('Light-gbm на исходных признаках с применением PCA. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(lgbm_preds, y_test)))","metadata":{"cellId":"xv34s24ces56zepdz2o2v","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"},{"output_type":"stream","name":"stdout","text":"Light-gbm на исходных признаках с применением PCA. Доля верных ответов на тестовой выборке: 0.87880\n\nCPU times: user 3min 37s, sys: 1min 27s, total: 5min 5s\nWall time: 1min 18s\n"}],"execution_count":399},{"cell_type":"markdown","source":"**Сравнение обучения Light-GBM и SVM c применением PCA:** Light-GBM обучается существенного быстрее, чем ядровой и линейный SVM. Однако при применении PCA Light-GBM немного уступает SVM по качеству предсказаний.\n\nПопробуем обучить Light-GBM на исходных признаках без применения PCA.","metadata":{"cellId":"xin5z2rx7r07jfrm404p12"}},{"cell_type":"code","source":"#!g1.1\n# подбор параметров для light-gbm без PCA\nlr = np.logspace(-4, 2, 11)\ntrees_number = [50, 100, 350]\ntuned_parameters = {'num_iterations' : trees_number, 'learning_rate' : lr, 'device' : ['gpu']}\n\nclf2 = GridSearchCV(lgbm.LGBMClassifier(), tuned_parameters, cv=5, scoring='accuracy', n_jobs=-1, verbose=3)\nclf2.fit(x_train_normed, y_train)\nclf2.results_","metadata":{"cellId":"de0uu7grzyga4jijv08pwn"},"outputs":[{"output_type":"stream","name":"stdout","text":"Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"},{"output_type":"stream","name":"stderr","text":"[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 68.5min\n[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 197.7min finished\n/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"},{"output_type":"display_data","data":{"text/plain":"GridSearchCV(cv=5, error_score=nan,\n             estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None,\n                                      colsample_bytree=1.0,\n                                      importance_type='split',\n                                      learning_rate=0.1, max_depth=-1,\n                                      min_child_samples=20,\n                                      min_child_weight=0.001,\n                                      min_split_gain=0.0, n_estimators=100,\n                                      n_jobs=-1, num_leaves=31, objective=None,\n                                      random_state=None, reg_alpha=0.0,\n                                      reg_lambda=0.0, silent=Tru...\n             iid='deprecated', n_jobs=-1,\n             param_grid={'device': ['gpu'],\n                         'learning_rate': array([1.00000000e-04, 4.64158883e-04, 2.15443469e-03, 1.00000000e-02,\n       4.64158883e-02, 2.15443469e-01, 1.00000000e+00, 4.64158883e+00,\n       2.15443469e+01, 1.00000000e+02]),\n                         'num_iterations': [100, 200, 350]},\n             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n             scoring='accuracy', verbose=1)"},"metadata":{}}],"execution_count":380},{"cell_type":"code","source":"#!g1.1\nclf2.best_params_","metadata":{"cellId":"xyy09kdsia8mptbah128r8","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"{'device': 'gpu', 'learning_rate': 0.21544346900318823, 'num_iterations': 350}"},"metadata":{}}],"execution_count":383},{"cell_type":"code","source":"#!g1.1\n%%time\nlgbm_clf2 = lgbm.LGBMClassifier(device='gpu', learning_rate = 0.21544346900318823, num_iterations = 350)\nlgbm_clf2.fit(x_train_normed, y_train)\nlgbm_preds2 = lgbm_clf2.predict(x_test_normed)\nprint('Light-gbm на исходных признаках без PCA. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(lgbm_preds2, y_test)))","metadata":{"cellId":"p5ufb6d7nf9jmxkncqkj7","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py:148: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"},{"output_type":"stream","name":"stdout","text":"Light-gbm на исходных признаках без PCA. Доля верных ответов на тестовой выборке: 0.91190\n\nCPU times: user 25min 54s, sys: 1min 33s, total: 27min 27s\nWall time: 5min 7s\n"}],"execution_count":402},{"cell_type":"markdown","source":"**Сравнение обучения Light-GBM и SVM на исходных признаках:** при использовании видео-карты Light-GBM существенно обгоняет SVM по времени. Благодаря обучению Light-GBM на всём множестве признаков без применения PCA, удалось добиться лучшего результата из всех моделей.\n\n**Итоговый вывод по всему заданию:** При обучении моделей на случайных признаках удалось добиться лучшего качества, чем на исходных, за исключением ядрового SVM на случайных признаках. Там качество ниже, поскольку ядровой метод применяется по сути дважды: сначала при апроксимации ядра, а потом и при обучении/предсказании. Light-GBM на исходных признаках показывает результаты лучше, чем SVM как для случайных признаков, так и для исходных, а также обошёл ядровой SVM на обоих видах признаков. Кроме этого, Light-GBM существенного обогнал по времени все рассмотренные ранее в этом задании алгоритмы. Таким образом, **с точки зрения эффективности применения на практике на имеющемся датасете целесообразно использовать Light-GBM.** Но, возможно, на других датасетах Light-GBM покажет качество ниже, чем ядровой SVM или SVM на случайных признаках. Кроме всего прочего, следует учитывать время на подбор гиперпараметров для Light-GBM. Если его принимать в расчёт, то SVM уже будет обгонять по времени Light-GBM.","metadata":{"cellId":"8032a9fboilu7n6mnyvmo"}},{"cell_type":"markdown","source":"__Задание 3. (2 балла)__\n\nПроведите эксперименты:\n1. Помогает ли предварительное понижение размерности с помощью PCA? \n2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n3. Важно ли, какую модель обучать — логистическую регрессию или SVM?","metadata":{"cellId":"1d183701-8c9e-4087-9ffe-1687f10a452f"}},{"cell_type":"markdown","source":"В предыдущем задании я провёл эксперименты, показывающие, что для Light-GBM понижение размерности оказывает негативное влияние на качество предсказаний, но при этом сокращается время обучения.","metadata":{"cellId":"k5pdoqwc3fefdmhep7qvd"}},{"cell_type":"code","source":"#!c1.8\n%%time\nlinear_kernel_without_pca = RFFPipeline(use_PCA=False, classifier='svm')\nlinear_kernel_without_pca.fit(x_train, y_train)\nlinear_preds_without_pca = linear_kernel_without_pca.predict(x_test)\nprint('Линейный SVM на случайных признаках без PCA. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(linear_preds_without_pca, y_test)))","metadata":{"cellId":"87d53aff-7385-43c1-8677-04eb431c8fa7","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Медиана посчитана: 0.79452\nЛинейный SVM на случайных признаках без PCA. Доля верных ответов на тестовой выборке: 0.85750\n\nCPU times: user 22min 7s, sys: 5.81 s, total: 22min 13s\nWall time: 22min 15s\n"}],"execution_count":405},{"cell_type":"code","source":"#!c1.8\n%%time\nrbf_kernel = SVC(kernel='rbf', random_state=72)\nunlinear_kernel_without_pca = RFFPipeline_New(model=rbf_kernel, use_PCA=False)\nunlinear_kernel_without_pca.fit(x_train, y_train)\nrbf_preds_without_pca = unlinear_kernel_without_pca.predict(x_test)\nprint('SVM с rbf-ядром на случайных признаках без PCA. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(rbf_preds_without_pca, y_test)))","metadata":{"cellId":"xfwpjkaebhywnntf74slm","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"SVM с rbf-ядром на случайных признаках без PCA. Доля верных ответов на тестовой выборке: 0.88000\n\nCPU times: user 19min 24s, sys: 4.26 s, total: 19min 28s\nWall time: 19min 22s\n"}],"execution_count":12},{"cell_type":"code","source":"#!c1.8\n%%time\nlogreg_kernel = RFFPipeline(use_PCA=False, classifier='logreg')\nlogreg_kernel.fit(x_train, y_train)\nlogreg_preds = logreg_kernel.predict(x_test)\nprint('Логистическая регрессия на случайных признаках без PCA. Доля верных ответов на тестовой выборке: {:.5f}\\n'.format(accuracy_score(logreg_preds, y_test)))","metadata":{"cellId":"gx4hoy3j37j8dvd3u0kgkb","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"Медиана посчитана: 0.78339\nЛогистическая регрессия на случайных признаках без PCA. Доля верных ответов на тестовой выборке: 0.86020\n\nCPU times: user 26 s, sys: 3.36 s, total: 29.4 s\nWall time: 8min 28s\n"}],"execution_count":7},{"cell_type":"code","source":"#!c1.8\n%%time\nrffp_kernel = RFFPipeline()\nrffp_kernel.fit(x_train, y_train)\npreds = rffp_kernel.predict(x_test)\nprint('Доля верных ответов на тестовой выборке:', accuracy_score(preds, y_test))","metadata":{"cellId":"4brn850y31udh341lonhdv","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"PCA применён\nМедиана посчитана: 0.63014\nДоля верных ответов на тестовой выборке: 0.879\nCPU times: user 35.6 s, sys: 22.1 s, total: 57.7 s\nWall time: 9min\n"}],"execution_count":407},{"cell_type":"markdown","source":"**Вопрос:** Помогает ли предварительное понижение размерности с помощью PCA?\n\n**Ответ:** Для разных моделей получились разные результаты, отменив понижение размерности для случайных признаков. Убрав понижение размерности исходного пространства признаков для логистической регрессии, качество предсказаний упало, время обучения увеличилось, но не на много. Для линейного SVM без PCA качество заметно упало по сравнению с вариантом с PCA, а время обучения тоже только увеличилось. Для ядрового SVM на случайных признаках, убрав понижение размерности, качество возросло, но и время обучения также увеличилось. В [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf) имперически показывается, что для успешного применения Random Fourier Features размерность нового пространства признаков должна быть больше размерности исходного пространства. До какого-то n_features чем оно больше, тем меньше ошибка апроксимации ядра для линейного SVM и логистической регрессии за счёт большего количество возможных приближений.","metadata":{"cellId":"397jsggwr3n02g7nne6u9ks"}},{"cell_type":"code","source":"#!c1.8\nfeatures_num = [350, 700, 1000, 1300, 1500, 2000, 2500, 3000, 3500]\n\nsvm_acc = []\nfor features in features_num:\n    linear2_rffp_kernel = RFFPipeline(n_features = features, classifier='svm')\n    linear2_rffp_kernel.fit(x_train, y_train)\n    preds = linear2_rffp_kernel.predict(x_test)\n    print('\\n', features, accuracy_score(preds, y_test))\n    svm_acc.append(accuracy_score(preds, y_test))","metadata":{"cellId":"emdk9swqt848nhls85qqjv","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"PCA применён\nМедиана посчитана: 0.62938\n\n 350 0.8684\nPCA применён\nМедиана посчитана: 0.64287\n\n 700 0.8795\nPCA применён\nМедиана посчитана: 0.63745\n\n 1000 0.8796\nPCA применён\nМедиана посчитана: 0.64292\n\n 1300 0.8809\nPCA применён\nМедиана посчитана: 0.63459\n\n 1500 0.8842\nPCA применён\nМедиана посчитана: 0.62395\n\n 2000 0.8841\nPCA применён\nМедиана посчитана: 0.63799\n\n 2500 0.8867\nPCA применён\nМедиана посчитана: 0.61757\n\n 3000 0.8818\nPCA применён\nМедиана посчитана: 0.63814\n\n 3500 0.8837\n"}],"execution_count":406},{"cell_type":"code","source":"#!c1.8\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nfig = plt.figure(figsize=(10,4))\naxes = fig.add_axes([0, 0, 1, 1])\n\naxes.plot(features_num, svm_acc, \"s-\")\naxes.set_title('Линейный SVM на случайных признаках. Зависимость accuracy от n_features', size=13)\naxes.set_xlabel('n_features')\naxes.set_ylabel('accuracy')\nplt.show()","metadata":{"cellId":"bfo4oxz0z5wjf90ftg8kcn","trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":410},{"cell_type":"code","source":"#!c1.8\nacc_array = []\nfor features in features_num:\n    linear2_rffp_kernel = RFFPipeline(n_features = features, classifier='logreg')\n    linear2_rffp_kernel.fit(x_train, y_train)\n    preds = linear2_rffp_kernel.predict(x_test)\n    print('\\n', features, accuracy_score(preds, y_test))\n    acc_array.append(accuracy_score(preds, y_test))","metadata":{"execution_id":"437e352d-458e-48ad-af3b-080aff51162a","cellId":"clhnftocru6pge0g76koog","trusted":true},"outputs":[{"output_type":"stream","name":"stdout","text":"PCA применён\nМедиана посчитана: 0.62931\n\n 350 0.8665\nPCA применён\nМедиана посчитана: 0.62891\n\n 700 0.8778\nPCA применён\nМедиана посчитана: 0.62971\n\n 1000 0.8799\nPCA применён\nМедиана посчитана: 0.62764\n\n 1300 0.8828\nPCA применён\nМедиана посчитана: 0.63464\n\n 1500 0.8816\nPCA применён\nМедиана посчитана: 0.63550\n\n 2000 0.8844\nPCA применён\nМедиана посчитана: 0.63278\n\n 2500 0.8856\nPCA применён\nМедиана посчитана: 0.64107\n"}],"execution_count":null},{"cell_type":"markdown","source":"**Вопрос**: Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n\n**Ответ:** С увеличением числа случайных признаков метрика качества также растёт. В [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf) сообщается, что при зафиксированном new_dim c ростом размерности случайных признаков (n_features) становится возможным добиться меньшей ошибки апроксимации. Можно сказать, что для линейного SVM при n_features > 1500 качество едва ли увеличивается, а выходит на плато. На графике для линейного SVM при n_features > 1500 можно видеть флуктуации значений accuracy даже при зафиксированном random_state модели. Это можно связать со случайностью инициализации самих весов и сдвигов, а также со случайностью выбора 1-го миллиона пар. Тем не менее, сильного роста метрики, как на первых шагах, не наблюдается.","metadata":{"cellId":"k5ya5ks048gw81mt7v2njc"}},{"cell_type":"markdown","source":"**Вопрос:** Важно ли, какую модель обучать — логистическую регрессию или SVM?\n\n**Ответ:** И линейный SVM и логистическая регрессия показывают сравнимо одинаковое качество предсказаний. При определённых конфигурациях модели SVM показывает качество чуть лучше, однако значительно дольше обучается, чем линейная регрессия. Таким образом, можно сделать вывод, что если качество до тысячных долей не играет особой роли, то лучше обучать логистическую регрессию, чтобы алгоритм отработал быстрее. Здесь также снова стоит отметить, что Light-GBM существенно обошёл все рассматриваемые модели как по качеству, так и по времени обучения.","metadata":{"cellId":"g8fq06nk0q5nlanpi2gxuo"}},{"cell_type":"markdown","source":"### Бонус","metadata":{"cellId":"f929d172-e9b7-4941-b8a4-9dd73bba2a2b"}},{"cell_type":"markdown","source":"__Задание 4. (Максимум 2 балла)__\n\nКак вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы.","metadata":{"cellId":"be06e29a-34de-4cae-a787-aa496be9b8ed"}},{"cell_type":"code","source":"# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪","metadata":{"cellId":"7803e4f3-9145-4f6a-890e-0a542c9d7584"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"__Задание 5. (Максимум 2 балла)__\n\nПоэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты.","metadata":{"cellId":"a9e5f9b2-8e37-4932-8538-a1ba4dfea501"}},{"cell_type":"code","source":"# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪","metadata":{"cellId":"cf552961-a637-4256-9a98-5d00065b27be"},"outputs":[],"execution_count":null}]}